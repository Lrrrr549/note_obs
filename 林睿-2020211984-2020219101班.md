# 大模型任务：ChatGLM系列

论文列表：

[1]Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others.2022.[GLM-130B: An Open Bilingual Pre-trained Model](https://arxiv.org/abs/2210.02414).arXiv:2210.02414
[2]Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. [GLM: General Language Model Pretraining with Autoregressive Blank Infilling](https://aclanthology.org/2022.acl-long.26). In _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 320–335, Dublin, Ireland. Association for Computational Linguistics.

# 自然语言处理相关任务：文本摘要

任务概述：

文本摘要是指通过各种技术，对文本或者是文本的集合，抽取、总结或是精炼其中的要点信息，用以概括和展示原始文本的主要内容或大意。随着互联网产生的文本数据越来越多，文本信息过载问题日益严重，对各类文本进行一个“降维”处理显得非常必要，文本摘要便是其中一个重要的手段。作为文本生成任务的主要方向之一，从本质上而言，这是一种信息压缩技术。文本摘要的目的就是为了让用户在当今世界海量的互联网数据中找到有效的信息。

论文列表：

[1]Abigail See and Peter J. Liu and Christopher D. Manning.2017.[ Get To The Point: Summarization with Pointer-Generator Networks](https://arxiv.org/abs/1704.04368v2).arXiv:1704.04368
[2]Mikhail S. Burtsev and Yuri Kuratov and Anton Peganov and Grigory V. Sapunov.2021.[Memory Transformer](https://arxiv.org/abs/2006.11527v2).arXiv:2006.11527
[3]Derek Tam and Anisha Mascarenhas and Shiyue Zhang and Sarah Kwan and Mohit Bansal and Colin Raffel.2022.[Evaluating the Factual Consistency of Large Language Models Through Summarization](https://arxiv.org/abs/2211.08412).arXiv:2211.08412